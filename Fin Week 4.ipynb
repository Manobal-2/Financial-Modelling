{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48a2e8c4-9d3f-49d1-97a8-c7598391097b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " TASK-1 SUCCESS\n",
      "Rows: 124\n",
      "        Close        date headline\n",
      "0  183.903229  2024-01-02         \n",
      "1  182.526230  2024-01-03         \n",
      "2  180.208130  2024-01-04         \n",
      "3  179.484940  2024-01-05         \n",
      "4  183.823959  2024-01-08         \n",
      " TASK 2 COMPLETE\n",
      "\n",
      "SENTIMENT–PRICE CORRELATION\n",
      "==================================================\n",
      "VADER   : r=nan, p-value=nan\n",
      "FinBERT : r=nan, p-value=nan\n",
      "\n",
      "TRADING SIGNALS\n",
      "==================================================\n",
      "VADER Buy: 0\n",
      "VADER Sell: 0\n",
      "FinBERT Buy: 0\n",
      "FinBERT Sell: 0\n",
      "\n",
      " WEEK 4 PIPELINE FINISHED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_30396\\3795930626.py:102: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  r_vader, p_vader = pearsonr(df[\"vader_sentiment\"], df[\"next_day_return\"])\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_30396\\3795930626.py:103: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  r_finbert, p_finbert = pearsonr(df[\"finbert_sentiment\"], df[\"next_day_return\"])\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "\n",
    "TICKER = \"AAPL\"\n",
    "START_DATE = \"2024-01-01\"\n",
    "END_DATE = \"2024-06-30\"\n",
    "\n",
    "\n",
    "prices_raw = yf.download(\n",
    "    TICKER,\n",
    "    start=START_DATE,\n",
    "    end=END_DATE,\n",
    "    progress=False\n",
    ")\n",
    "\n",
    "prices_raw.columns = [c[0] if isinstance(c, tuple) else c for c in prices_raw.columns]\n",
    "\n",
    "prices = prices_raw.reset_index()[[\"Date\", \"Close\"]]\n",
    "prices[\"date\"] = pd.to_datetime(prices[\"Date\"]).dt.date\n",
    "prices = prices.drop(columns=[\"Date\"])\n",
    "\n",
    "\n",
    "news = pd.read_csv(\"financial_news_events.csv\")\n",
    "news.columns = news.columns.str.lower()\n",
    "\n",
    "date_col = next(\n",
    "    c for c in [\"date\", \"published_at\", \"timestamp\", \"time\"]\n",
    "    if c in news.columns\n",
    ")\n",
    "\n",
    "news[\"date\"] = pd.to_datetime(news[date_col], errors=\"coerce\").dt.date\n",
    "news = news.dropna(subset=[\"date\"])\n",
    "\n",
    "headline_col = next(\n",
    "    c for c in [\"headline\", \"title\", \"text\"]\n",
    "    if c in news.columns\n",
    ")\n",
    "\n",
    "news[\"headline\"] = news[headline_col].astype(str)\n",
    "\n",
    "if \"ticker\" in news.columns:\n",
    "    news = news[news[\"ticker\"] == TICKER]\n",
    "\n",
    "\n",
    "news_daily = (\n",
    "    news.groupby(\"date\", as_index=False)[\"headline\"]\n",
    "    .apply(lambda x: \" \".join(x))\n",
    ")\n",
    "\n",
    "\n",
    "df = prices.merge(news_daily, on=\"date\", how=\"left\")\n",
    "df[\"headline\"] = df[\"headline\"].fillna(\"\")\n",
    "\n",
    "\n",
    "assert isinstance(df.columns, pd.Index)\n",
    "assert df[\"Close\"].isna().sum() == 0\n",
    "\n",
    "print(\" TASK-1 SUCCESS\")\n",
    "print(\"Rows:\", len(df))\n",
    "print(df.head())\n",
    "\n",
    "\n",
    "\n",
    "vader = SentimentIntensityAnalyzer()\n",
    "df[\"vader_sentiment\"] = df[\"headline\"].apply(\n",
    "    lambda x: vader.polarity_scores(x)[\"compound\"]\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ProsusAI/finbert\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"ProsusAI/finbert\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "def finbert_score(text):\n",
    "    inputs = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        max_length=128\n",
    "    ).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    probs = torch.softmax(outputs.logits, dim=-1)[0]\n",
    "    return (probs[2] - probs[0]).item()\n",
    "\n",
    "df[\"finbert_sentiment\"] = df[\"headline\"].apply(finbert_score)\n",
    "\n",
    "print(\" TASK 2 COMPLETE\")\n",
    "\n",
    "\n",
    "df[\"daily_return\"] = df[\"Close\"].pct_change()\n",
    "df[\"next_day_return\"] = df[\"daily_return\"].shift(-1)\n",
    "df = df.dropna()\n",
    "\n",
    "r_vader, p_vader = pearsonr(df[\"vader_sentiment\"], df[\"next_day_return\"])\n",
    "r_finbert, p_finbert = pearsonr(df[\"finbert_sentiment\"], df[\"next_day_return\"])\n",
    "\n",
    "print(\"\\nSENTIMENT–PRICE CORRELATION\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"VADER   : r={r_vader:.3f}, p-value={p_vader:.4f}\")\n",
    "print(f\"FinBERT : r={r_finbert:.3f}, p-value={p_finbert:.4f}\")\n",
    "\n",
    "def signal(score, threshold=0.3):\n",
    "    if score > threshold:\n",
    "        return 1\n",
    "    elif score < -threshold:\n",
    "        return -1\n",
    "    return 0\n",
    "\n",
    "df[\"signal_vader\"] = df[\"vader_sentiment\"].apply(signal)\n",
    "df[\"signal_finbert\"] = df[\"finbert_sentiment\"].apply(signal)\n",
    "\n",
    "print(\"\\nTRADING SIGNALS\")\n",
    "print(\"=\" * 50)\n",
    "print(\"VADER Buy:\", (df[\"signal_vader\"] == 1).sum())\n",
    "print(\"VADER Sell:\", (df[\"signal_vader\"] == -1).sum())\n",
    "print(\"FinBERT Buy:\", (df[\"signal_finbert\"] == 1).sum())\n",
    "print(\"FinBERT Sell:\", (df[\"signal_finbert\"] == -1).sum())\n",
    "\n",
    "print(\"\\n WEEK 4 PIPELINE FINISHED\")\n",
    "\n",
    "df_combined = pd.merge(\n",
    "    prices[[\"date\", \"Close\"]],\n",
    "    news_daily,\n",
    "    on=\"date\",\n",
    "    how=\"inner\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7e38e80-a772-4b2f-9187-09a1512fc16e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Week-4 output saved correctly\n"
     ]
    }
   ],
   "source": [
    "df_combined.to_csv(\"df_combined_week4.csv\", index=False)\n",
    "print(\"✅ Week-4 output saved correctly\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff92bcc-0eda-4117-ac7b-29c0486e1b20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
